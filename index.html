<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Zifan  Xu


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <meta name="google-site-verification" content="gQHyRCeiNn_Ih-WkwTt2qrb74bkQQn7EMFEk-b8c5k0" />
  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Zifan</span>  Xu
    </h1>
     <p class="desc"><a href="https://www.cs.utexas.edu/~pstone/" target="_blank" rel="noopener noreferrer">LARG</a> | <a href="https://www.cs.utexas.edu/" target="_blank" rel="noopener noreferrer">UTCS</a> | <a href="https://robotics.utexas.edu/" target="_blank" rel="noopener noreferrer">Texas Robotic</a> | zfxu [at] utexas.edu</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/IMG_6461_cropped.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>I am a Ph.D. student of Computer Science at University of Texas at Austin. I am very honored to be advised by <a href="https://www.cs.utexas.edu/~pstone/" target="_blank" rel="noopener noreferrer">Prof. Peter Stone</a>. I have general interests in reinforcement learning, meta learning, curriculum learning, and their applicaitons in robotics. My primiary focus is to apply deep reinforcement learning for mobile robot autonomous navigation.</p>

<p>Before I started the CS program, I recieved masterâ€™s and bachelorâ€™s degrees in Physics, but was lucky to find my passion in artificial intellegence. Feel free to reach out to me if you are curious about my experience and research!</p>

<p>Contact: <a href="mailto:zfxu@utexas.edu">Email</a> / <a href="https://github.com/Daffan" target="_blank" rel="noopener noreferrer">Github</a> / <a href="https://scholar.google.com/citations?user=d6Hj8JQAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a> / <a href="https://twitter.com/JefferyXu4" target="_blank" rel="noopener noreferrer">Twitter</a></p>

    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Dec 5, 2023</th>
          <td>
            
              We presented one paper for R0-FoMo workshop at NeurIPS 2023.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 1, 2023</th>
          <td>
            
              Our MM-ACL paper is selected for an oral presentation at CoLLAs 2023!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 28, 2023</th>
          <td>
            
              We organized <a href="https://people.cs.gmu.edu/~xiao/Research/BARN_Challenge/BARN_Challenge23.html" target="_blank" rel="noopener noreferrer">The BARN Challenge</a> at ICRA 2023 in London.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Publications</h2>
  <h4>Preprint</h4>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/RSD.png">
      
    
  </div>

  <div id="xu2023latent" class="col-sm-8">
    
      <div class="title">Latent Skill Discovery for Chain-of-Thought Reasoning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Haozhu Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dmitriy Bespalov,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peter Stone,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Yanjun Qi
                
              
            
          
        
      </div>

      <div class="aaa">
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">xu2023latent</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">preprint</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Latent Skill Discovery for Chain-of-Thought Reasoning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Wang, Haozhu and Bespalov, Dmitriy and Stone, Peter and Qi, Yanjun}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2312.04684}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{RSD.png}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
  <h4>Journal</h4>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/appl.png">
      
    
  </div>

  <div id="ras22-xiao" class="col-sm-8">
    
      <div class="title">APPL: Adaptive Planner Parameter Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zizhao Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bo Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                   Gauraang Dhamankar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Garrett Warnell,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>Robotics and Autonomous Systems</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ras22-xiao.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While current autonomous navigation systems allow robots to successfully drive themselves from one point to another in specific environments, they typically require extensive manual parameter re-tuning by human robotics experts in order to function in new environments. Furthermore, even for just one complex environment, a single set of fine-tuned parameters may not work well in different regions of that environment. These problems prohibit reliable mobile robot deployment by non-expert users. As a remedy, we propose Adaptive Planner Parameter Learning (APPL), a machine learning framework that can leverage non-expert human interaction via several modalities Ã¢â‚¬â€œ including teleoperated demonstrations, corrective interventions, and evaluative feedback Ã¢â‚¬â€œ and also unsupervised reinforcement learning to learn a parameter policy that can dynamically adjust the parameters of classical navigation systems in response to changes in the environment. APPL inherits safety and explainability from classical navigation systems while also enjoying the benefits of machine learning, i.e., the ability to adapt and improve from experience. We present a suite of individual appl methods and also a unifying cycle-oflearning scheme that combines all the proposed methods in a framework that can improve navigation performance through continual, iterative human interaction and simulation training.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ras22-xiao</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">is_journal</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{APPL: Adaptive Planner Parameter Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xiao, Xuesu and Wang, Zizhao and Xu, Zifan and Liu, Bo and abd Gauraang Dhamankar and Nair, Anirudh and Warnell, Garrett and Stone, Peter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Robotics and Autonomous Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{appl.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ras22-xiao.pdf}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
  <h4>Conference</h4>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/navbenchmark.png">
      
    
  </div>

  <div id="NavBench-ZIFAN" class="col-sm-8">
    
      <div class="title">Benchmarking Reinforcement Learning Techniques for Autonomous Navigation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bo Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA 2023)</em>
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/navbenchmark.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">NavBench-ZIFAN</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preprint</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Benchmarking Reinforcement Learning Techniques for Autonomous Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Liu, Bo and Nair, Anirudh and Xiao, Xuesu and Stone, Peter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA 2023)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{London, England}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{navbenchmark.pdf}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{navbenchmark.png}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/dyna_barn.png">
      
    
  </div>

  <div id="DynaBARN-ANI" class="col-sm-8">
    
      <div class="title">DynaBARN: Benchmarking Metric Ground Navigation in Dynamic Environments</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fulin Jiang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kang Hou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shuozhe Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and  Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>International Symposium on Safety, Security, and Rescue Robotics (SSRR) 2022</em>
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/dyna_barn.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DynaBARN-ANI</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preprint</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DynaBARN: Benchmarking Metric Ground Navigation in Dynamic Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nair, Anirudh and Jiang, Fulin and Hou, Kang and Xu, Zifan and Li, Shuozhe and Xiao, Xuesu and and Peter Stone}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Symposium on Safety, Security, and Rescue Robotics (SSRR) 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Seville, Spain}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{dyna_barn.pdf}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{dyna_barn.png}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/MM-ACL-ZIFAN.png">
      
    
  </div>

  <div id="MM-ACL-ZIFAN" class="col-sm-8">
    
      <div class="title">Model-Based Meta Automatic Curriculum Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yulin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shahaf S. Shperberg,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yuqian Jiang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Reuth Mirsky,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bo Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>Conference on Lifelong Learning Agents (CoLLAs) 2023</em>
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/MM_ACL_CoLLAs2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MM-ACL-ZIFAN</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preprint</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model-Based Meta Automatic Curriculum Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Zhang, Yulin and Shperberg, Shahaf S. and Jiang, Yuqian and Mirsky, Reuth and Liu, Bo and Stone, Peter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Conference on Lifelong Learning Agents (CoLLAs) 2023}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{MM_ACL_CoLLAs2023.pdf}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{MM-ACL-ZIFAN.png}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/wang-icml22-cdl.png">
      
    
  </div>

  <div id="ICML22-wang" class="col-sm-8">
    
      <div class="title">Causal Dynamics Learning for Task-Independent State Abstraction</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Zizhao Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yuke Zhu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Proceedings of the 39th International Conference on Machine Learning (ICML2022),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ICML22-wang.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Learning dynamics models accurately is an important goal for Model-Based Reinforcement Learning (MBRL), but most MBRL methods learn a dense dynamics model which is vulnerable to spurious correlations and therefore generalizes poorly to unseen states. In this paper, we introduce Causal Dynamics Learning for Task-Independent State Abstraction (CDL), which first learns a theoretically proved causal dynamics model that removes unnecessary dependencies between state variables and the action, thus generalizing well to unseen states. A state abstraction can then be derived from the learned dynamics, which not only improves sample efficiency but also applies to a wider range of tasks than existing state abstraction methods. Evaluated on two simulated environments and downstream tasks, both the dynamics model and policies learned by the proposed method generalize well to unseen states and the derived state abstraction improves sample efficiency compared to learning without it.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICML22-wang</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zizhao and Xiao, Xuesu and Xu, Zifan and Zhu, Yuke and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Causal Dynamics Learning for Task-Independent State Abstraction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 39th International Conference on Machine Learning (ICML2022)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Baltimore, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{wang-icml22-cdl.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ICML22-wang.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <a href="https://www.cs.utexas.edu/users/xiao/Research/APPL/APPL.html" target="_blank" rel="noopener noreferrer"><img class="img-fluid z-depth-1 rounded" src="/assets/img/applr.png"></a>
      
    
  </div>

  <div id="icra21-xu" class="col-sm-8">
    
      <div class="title">APPLR: Adaptive Planner Parameter Learning from Reinforcement</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gauraang Dhamankar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Garrett Warnell,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bo Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zizhao Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA 2021),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/icra21-xu.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Daffan/ros_jackal" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      <a href="https://www.youtube.com/watch?v=JKHTAowdGUk&amp;t=26s" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/icra21-xu.slides.pptx" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
      
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Classical navigation systems typically operate using a fixed set of hand-picked parameters (e.g. maximum speed, sampling rate, inflation radius, etc.) and require heavy expert re-tuning in order to work in new environments. To mitigate this requirement, it has been proposed to learn parameters for different contexts in a new environment using human demonstrations collected via teleoperation. However, learning from human demonstration limits deployment to the training environment, and limits overall performance to that of a potentially-suboptimal demonstrator. In this paper, we introduce APPLR, Adaptive Planner Parameter Learning from Reinforcement, which allows existing navigation systems to adapt to new scenarios by using a parameter selection scheme discovered via reinforcement learning (RL) in a wide variety of simulation environments. We evaluate APPLR on a robot in both simulated and physical experiments, and show that it can outperform both a fixed set of hand-tuned parameters and also a dynamic parameter tuning scheme learned from human demonstration.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">icra21-xu</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Dhamankar, Gauraang and Nair, Anirudh and Xiao, Xuesu and Warnell, Garrett and Liu, Bo and Wang, Zizhao and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{APPLR: Adaptive Planner Parameter Learning from Reinforcement}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA 2021)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Xi'an, China}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{applr.png}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/Daffan/ros_jackal}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=JKHTAowdGUk&amp;t=26s}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/icra21-xu.pdf}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/icra21-xu.slides.pptx}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/xiao/Research/APPL/APPL.html}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/ssrr.png">
      
    
  </div>

  <div id="ssrr2021-xu" class="col-sm-8">
    
      <div class="title">Machine Learning Methods for Local Motion Planning: A Study of End-to-End vs. Parameter Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Garrett Warnell,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Proceedings of the 2021 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2021),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ssrr2021-xu.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Daffan/ros_jackal" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      <a href="https://www.youtube.com/watch?v=U592HQ30TsY&amp;t=6s" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While decades of research efforts have been devoted to developing classical autonomous navigation systems to move robots from one point to another in a collision-free manner, machine learning approaches to navigation have been recently proposed to learn navigation behaviors from data. Two representative paradigms are end-to-end learning (directly from perception to motion) and parameter learning (from perception to parameters used by a classical underlying planner). These two types of methods are believed to have complementary pros and cons: parameter learning is expected to be robust to different scenarios, have provable guarantees, and exhibit explainable behaviors; end-to-end learning does not require extensive engineering and has the potential to outperform approaches that rely on classical systems. However, these beliefs have not been verified through real-world experiments in a comprehensive way. In this paper, we report on an extensive study to compare end-to-end and parameter learning for local motion planners in a large suite of simulated and physical experiments. In particular, we test the performance of end-to-end motion policies, which directly compute raw motor commands, and parameter policies, which compute parameters to be used by classical planners, with different inputs (e.g., raw sensor data, costmaps), and provide an analysis of the results.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ssrr2021-xu</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Xiao, Xuesu and Warnell, Garrett and Nair, Anirudh and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine Learning Methods for Local Motion Planning: A Study of End-to-End vs. Parameter Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2021)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New York, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{ssrr.png}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/Daffan/ros_jackal}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=U592HQ30TsY&amp;t=6s}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ssrr2021-xu.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <a href="http://scavenger-hunt.cs.utexas.edu/" target="_blank" rel="noopener noreferrer"><img class="img-fluid z-depth-1 rounded" src="/assets/img/scavenger_hunt.png"></a>
      
    
  </div>

  <div id="ICRA21-Yedidsion" class="col-sm-8">
    
      <div class="title">A Scavenger Hunt for Service Robots</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Harel Yedidsion,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jennifer Suriadinata,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Stefan Debruyn,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Proceedings of the 2021 International Conference on Robotics and Automation (ICRA 2021),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ICRA21-Yedidsion.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Daffan/scavenger_hunt_sim" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      <a href="http://scavenger-hunt.cs.utexas.edu/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
	Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. 
	One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. 
	This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem.  In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found.  
	We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance.
	In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts. 
	</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICRA21-Yedidsion</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yedidsion, Harel and Suriadinata, Jennifer and Xu, Zifan and Debruyn, Stefan and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Scavenger Hunt for Service Robots}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 International Conference on Robotics and Automation (ICRA 2021)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Xi'an China}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{scavenger_hunt.png}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/Daffan/scavenger_hunt_sim}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{http://scavenger-hunt.cs.utexas.edu/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/ICRA21-Yedidsion.pdf}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{http://scavenger-hunt.cs.utexas.edu/}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>
  <h4>Workshop / Extended Abstract / Technical Report</h4>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/ses.png">
      
    
  </div>

  <div id="SES-ZIFAN" class="col-sm-8">
    
      <div class="title">Learning Real-world Autonomous Navigation by Self-Supervised Environment Synthesis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anirudh Nair,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xuesu Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In First Workshop on Photorealistic Image and Environment Synthesis for Robotics (PIES-Rob) at IROS 2023,</em>
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/learning_ses.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SES-ZIFAN</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">is_other</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Real-world Autonomous Navigation by Self-Supervised Environment Synthesis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Nair, Anirudh and Xiao, Xuesu and Stone, Peter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{First Workshop on Photorealistic Image and Environment Synthesis for Robotics (PIES-Rob) at IROS 2023}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Detroit, Michigan, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{learning_ses.pdf}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{ses.png}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/DARL22-REUTH.png">
      
    
  </div>

  <div id="DARL22-REUTH" class="col-sm-8">
    
      <div class="title">Task Factorization in Curriculum Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Reuth Mirsky,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shahaf S. Shperberg,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yulin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yuqian Jiang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jiaxun Cui,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Decision Awareness in Reinforcement Learning (DARL) workshop at the 39th International Conference on Machine Learning (ICML),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/DARL22-REUTH.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A common challenge for learning when applied to a complex â€œtargetâ€ task is that learning that task all at once can be too difficult due to inefficient exploration given a sparse reward signal.  Curriculum Learning addresses this challenge by sequencing training tasks for a learner to facilitate gradual learning. One of the crucial steps in finding a suitable curriculum learning approach is to understand the dimensions along which the domain can be factorized. In this paper, we identify different types of factorizations common in the literature of curriculum learning for reinforcement learning tasks: factorizations that involve the agent, the environment, or the mission. For each factorization category, we identify the relevant algorithms and techniques that leverage that factorization and present several case studies to showcase how leveraging an appropriate factorization can boost learning using a simple curriculum.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DARL22-REUTH</span><span class="p">,</span>
  <span class="na">is_other</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mirsky, Reuth and Shperberg, Shahaf S. and Zhang, Yulin and Xu, Zifan and Jiang, Yuqian and Cui, Jiaxun and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Task Factorization in Curriculum Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Decision Awareness in Reinforcement Learning (DARL) workshop at the 39th International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Baltimore, Maryland, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{DARL22-REUTH.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/DARL22-REUTH.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/GOLD-FACTUAL-LIYAN.png">
      
    
  </div>

  <div id="GOLD-FACTUAL-LIYAN" class="col-sm-8">
    
      <div class="title">GOLD-FACTUAL: Learning to Generate Faithful Summaries from Modelsâ€™ Generations</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liyan Tang
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>CS394R Final Project</em>
         
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/GOLD-FACTUAL-LIYAN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">GOLD-FACTUAL-LIYAN</span><span class="p">,</span>
  <span class="na">is_other</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Tang, Liyan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GOLD-FACTUAL: Learning to Generate Faithful Summaries from Modelsâ€™ Generations}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CS394R Final Project}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{GOLD-FACTUAL-LIYAN.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{GOLD-FACTUAL-LIYAN.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3 figure">
    
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/DARL22-ZIFAN.png">
      
    
  </div>

  <div id="DARL22-ZIFAN" class="col-sm-8">
    
      <div class="title">Model-Based Meta Automatic Curriculum Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zifan Xu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yulin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shahaf S. Shperberg,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Reuth Mirsky,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yulin Zhan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yuqian Jiang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bo Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter Stone
                
              
            
          
        
      </div>

      <div class="aaa">
        
          <em>In Decision Awareness in Reinforcement Learning (DARL) workshop at the 39th International Conference on Machine Learning (ICML),</em>
         
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/DARL22-ZIFAN.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>When an agent trains for one target task, its experience is expected to be useful for training on another target task. This paper formulates the meta curriculum learning problem that builds a sequence of intermediate training tasks, called a curriculum, which will assist the learner to train toward any given target task in general. We propose a model-based meta automatic curriculum learning algorithm (MM-ACL) that learns to predict the performance improvement on one task when the policy is trained on another, given contextual information such as the history of training tasks, loss functions, rollout state-action trajectories from the policy, etc. This predictor facilitates the generation of curricula that optimizes the performance of the learner on different target tasks. Our empirical results demonstrate that MM-ACL outperforms a random curriculum, a manually created curriculum, and a commonly used non-stationary bandit algorithm in a GridWorld domain.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DARL22-ZIFAN</span><span class="p">,</span>
  <span class="na">is_other</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zifan and Zhang, Yulin and Shperberg, Shahaf S. and Mirsky, Reuth and Zhan, Yulin and Jiang, Yuqian and Liu, Bo and Stone, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model-Based Meta Automatic Curriculum Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Decision Awareness in Reinforcement Learning (DARL) workshop at the 39th International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Baltimore, Maryland, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">figure</span> <span class="p">=</span> <span class="s">{DARL22-ZIFAN.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.cs.utexas.edu/users/pstone/Papers/bib2html-links/DARL22-ZIFAN.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2024 Zifan  Xu.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
